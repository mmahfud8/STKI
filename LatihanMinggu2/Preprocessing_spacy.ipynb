{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9ab14c6-31e4-46fb-bc5c-3514af2c3a50",
   "metadata": {},
   "source": [
    "Perbedaan NLTK dan Spacy\n",
    "Spacy is better than NLTK in terms of performance.Here, there are some comparison\n",
    "\n",
    "1- NLTK is a string processing library. It takes strings as input and returns strings or lists of strings as output.Whereas, spaCy uses object-oriented approach.When we parse a text, spaCy returns document object whose words and sentences are objects themselves.\n",
    "\n",
    "2- spaCy has support for word vectors whereas NLTK does not.\n",
    "\n",
    "3- In word tokenization and POS-tagging spaCy performs better, but in sentence tokenization, NLTK outperforms spaCy.\n",
    "\n",
    "4- NLTK supports various languages whereas spaCy have statistical models for 7 languages (English, German, Spanish, French, Portuguese, Italian, and Dutch). It also supports named entities for multi language.\n",
    "                                                                        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d61e44b-bee9-456c-8574-73175de6f4ee",
   "metadata": {},
   "source": [
    "NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44ed8b0b-c744-4538-a522-7126d3ffe28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# token\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "def word_tokenize_wrapper(text):\n",
    "  return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48e48e6c-2f5b-4cd8-8b63-f42b3507513e",
   "metadata": {},
   "outputs": [],
   "source": [
    "teks_nltk = word_tokenize_wrapper('Yahya beserta teman-teman TK suka melihat lumba-lumba di Batang Dolphin Center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64078a55-8ee2-4fa8-b04a-0970d918b72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Yahya',\n",
       " 'beserta',\n",
       " 'teman-teman',\n",
       " 'TK',\n",
       " 'suka',\n",
       " 'melihat',\n",
       " 'lumba-lumba',\n",
       " 'di',\n",
       " 'Batang',\n",
       " 'Dolphin',\n",
       " 'Center']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teks_nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c249eb0b-a002-4579-9bda-1123101fb0ca",
   "metadata": {},
   "source": [
    "spacy\n",
    "lakukan installasi dan update lib spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afb5a298-549c-4458-84ca-1990f62c70db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.id import Indonesian\n",
    "import spacy\n",
    "\n",
    "nlp = Indonesian()  # use directly\n",
    "nlp = spacy.blank('id')  # blank instance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8ded7a3-a3a0-471b-a2e6-90dd282f619b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Teks = nlp('Yahya beserta teman-teman TK suka melihat lumba-lumba di Batang Dolphin Center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be35d8d5-3e5c-497a-8ea5-51eff6e8c5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Token_kata = [token.text for token in Teks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aab842dd-af18-4ff7-844e-5d46f0e975ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Yahya',\n",
       " 'beserta',\n",
       " 'teman-teman',\n",
       " 'TK',\n",
       " 'suka',\n",
       " 'melihat',\n",
       " 'lumba-lumba',\n",
       " 'di',\n",
       " 'Batang',\n",
       " 'Dolphin',\n",
       " 'Center']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Token_kata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a3eef1-d1c2-4328-b6a7-777d2fc83b6d",
   "metadata": {},
   "source": [
    "load library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e17a9fa1-5742-421e-86d1-e7723a273d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import time\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26217176-46b4-48d9-882f-bf6dbd279df9",
   "metadata": {},
   "source": [
    "load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6601c22d-6ec9-4535-9b29-3336ded300b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2acddd6d-a3cd-448f-b842-a7295c7e98e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"2018-01-01/01/00/1514764800000.republika.387b7eb869.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "619cc642-5382-4fe5-b754-66e884647748",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file) as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b929e12a-455d-4481-b2a0-10da3f1ed707",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.json_normalize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e078a48-db1d-449a-a8cf-7ed65bb65618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://khazanah.republika.co.id/berita/dunia-i...</td>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>Dzikir Nasional Siapkan Spiritual untuk Lebih ...</td>\n",
       "      <td>REPUBLIKA.CO.ID, JAKARTA -- Dzikir Nasional 20...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url                 date  \\\n",
       "0  http://khazanah.republika.co.id/berita/dunia-i...  2018-01-01 00:00:00   \n",
       "\n",
       "                                               title  \\\n",
       "0  Dzikir Nasional Siapkan Spiritual untuk Lebih ...   \n",
       "\n",
       "                                             content  \n",
       "0  REPUBLIKA.CO.ID, JAKARTA -- Dzikir Nasional 20...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97de2e98-f918-462c-ab0d-846723b73407",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['url'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "babd3240-8954-4ec5-ae5f-a078da7b4608",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c249e633-da84-4fe9-81a6-8a706f682452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dzikir Nasional Siapkan Spiritual untuk Lebih ...</td>\n",
       "      <td>REPUBLIKA.CO.ID, JAKARTA -- Dzikir Nasional 20...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Dzikir Nasional Siapkan Spiritual untuk Lebih ...   \n",
       "\n",
       "                                             content  \n",
       "0  REPUBLIKA.CO.ID, JAKARTA -- Dzikir Nasional 20...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7477d4c9-b4c1-454c-9c7b-639233ac1753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 0 to 0\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   title    1 non-null      object\n",
      " 1   content  1 non-null      object\n",
      "dtypes: object(2)\n",
      "memory usage: 148.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3ea433-cb43-4265-a0dd-f72c86a412b2",
   "metadata": {},
   "source": [
    "Preprocessing dataset\n",
    "\n",
    "kita akan pakai modul dari AMS 01-03\r\n",
    "\r\n",
    "disamping itu kita akan memakai modul https://github.com/cbaziotis/ekphrasis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e52ba0d3-f724-4d80-9aca-5e78b3100376",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python311\\Lib\\site-packages\\ekphrasis\\classes\\tokenizer.py:225: FutureWarning: Possible nested set at position 2190\n",
      "  self.tok = re.compile(r\"({})\".format(\"|\".join(pipeline)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python311\\Lib\\site-packages\\ekphrasis\\classes\\exmanager.py:14: FutureWarning: Possible nested set at position 42\n",
      "  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in\n"
     ]
    }
   ],
   "source": [
    "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
    "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
    "from ekphrasis.dicts.emoticons import emoticons\n",
    "\n",
    "text_processor = TextPreProcessor(\n",
    "    # terms that will be normalized\n",
    "    normalize=['email', 'percent', 'money', 'phone', 'user',\n",
    "        'time', 'date', 'number'],\n",
    "    # terms that will be annotated\n",
    "    #annotate={\"hashtag\", \"allcaps\", \"elongated\", \"repeated\",'emphasis', 'censored'},\n",
    "    annotate={\"hashtag\"},\n",
    "    fix_html=True,  # fix HTML tokens\n",
    "    \n",
    "    # corpus from which the word statistics are going to be used \n",
    "    # for word segmentation \n",
    "    segmenter=\"twitter\", \n",
    "    \n",
    "    # corpus from which the word statistics are going to be used \n",
    "    # for spell correction\n",
    "    corrector=\"twitter\", \n",
    "    \n",
    "    unpack_hashtags=True,  # perform word segmentation on hashtags\n",
    "    unpack_contractions=True,  # Unpack contractions (can't -> can not)\n",
    "    spell_correct_elong=False,  # spell correction for elongated words\n",
    "    \n",
    "    # select a tokenizer. You can use SocialTokenizer, or pass your own\n",
    "    # the tokenizer, should take as input a string and return a list of tokens\n",
    "    tokenizer=SocialTokenizer(lowercase=True).tokenize,\n",
    "    \n",
    "    # list of dictionaries, for replacing tokens extracted from the text,\n",
    "    # with other expressions. You can pass more than one dictionaries.\n",
    "    dicts=[emoticons]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db40fd4d-4812-40a0-a678-671401ec1d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# panggil ekphrasis\n",
    "\n",
    "def bersih_data(text):\n",
    "    return \" \".join(text_processor.pre_process_doc(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b78b17d-465f-4dbb-9633-99f65f9416f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fungsi dari AMS 01-03. silakan cek bagaimana saya merubah menjadi fungsi\n",
    "\n",
    "def non_ascii(text):\n",
    "    return text.encode('ascii', 'replace').decode('ascii')\n",
    "\n",
    "def remove_space_alzami(text):\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "def remove_emoji_alzami(text):\n",
    "    return ' '.join(re.sub(\"([x#][A-Za-z0-9]+)\",\" \", text).split())\n",
    "\n",
    "def remove_tab(text):\n",
    "    return text.replace('\\\\t',\" \").replace('\\\\n',\" \").replace('\\\\u',\" \").replace('\\\\',\"\")\n",
    "\n",
    "def remove_tab2(text):\n",
    "    return re.sub('\\s+',' ',text)\n",
    "\n",
    "def remove_rt(text):\n",
    "    return text.replace('rt',\" \")\n",
    "\n",
    "def remove_mention(text):\n",
    "    return ' '.join(re.sub(\"([@#][A-Za-z0-9]+)|(\\w+:\\/\\/\\S+)\",\" \", text).split())\n",
    "\n",
    "def remove_incomplete_url(text):\n",
    "    return text.replace(\"http://\", \" \").replace(\"https://\", \" \")\n",
    "\n",
    "def remove_single_char(text):\n",
    "    return re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
    "\n",
    "def remove_excessive_dot(text):\n",
    "    return text.replace('..',\" \")\n",
    "\n",
    "def change_stripe(text):\n",
    "    return text.replace('-',\" \")\n",
    "\n",
    "def lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_single_char(text):\n",
    "    return re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
    "\n",
    "def remove_excessive_dot(text):\n",
    "    return text.replace('..',\" \")\n",
    "\n",
    "def lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_whitespace_LT(text):\n",
    "    return text.strip()\n",
    "\n",
    "def remove_whitespace_multiple(text):\n",
    "    return re.sub('\\s+',' ',text)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    remove = string.punctuation\n",
    "    remove = remove.replace(\"_\", \"\") # don't remove hyphens\n",
    "    pattern = r\"[{}]\".format(remove) # create the pattern\n",
    "    return re.sub(pattern, \"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9318bb3e-3e29-4544-b64f-89094a88b0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hapus untuk <>\n",
    "def remove_number_eks(text):\n",
    "    return text.replace('<number>',\" \")\n",
    "\n",
    "def remove_angka(text):\n",
    "    return re.sub(r\"\\d+\", \"\", text) \n",
    "\n",
    "def remove_URL_eks(text):\n",
    "    return text.replace('URL',\" \").replace('url',\" \")\n",
    "\n",
    "def space_punctuation(text):\n",
    "    return re.sub('(?<! )(?=[.,!?()])|(?<=[.,!?()])(?! )', r' ', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dd9933-d5e3-4457-a01a-370958254a0a",
   "metadata": {},
   "source": [
    "lakukan pembersihan dengan memanggil fungsi yang didefinisikan diatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10c6f98b-cf8d-4e7b-9d1b-a98bd825cf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "final_string = []\n",
    "s = \"\"\n",
    "for text in df['content'].values:\n",
    "    filteredSentence = []\n",
    "    EachReviewText = \"\"\n",
    "    proc = lower(text)\n",
    "    proc = change_stripe(text)\n",
    "    proc = remove_emoji_alzami(proc)\n",
    "    proc = remove_tab(proc)\n",
    "    proc = remove_tab2(proc)\n",
    "    proc = non_ascii(proc)\n",
    "    proc = remove_incomplete_url(proc)\n",
    "    proc = remove_excessive_dot(proc)\n",
    "    proc = remove_whitespace_LT(proc)\n",
    "    proc = remove_whitespace_multiple(proc)\n",
    "    proc = remove_single_char(proc)\n",
    "    proc = space_punctuation(proc)\n",
    "    proc = remove_punctuation(proc)\n",
    "    proc = remove_space_alzami(proc)\n",
    "    proc = bersih_data(proc)\n",
    "    #proc = remove_rt(proc)\n",
    "    proc = remove_number_eks(proc)\n",
    "    proc = remove_angka(proc) \n",
    "    proc = remove_URL_eks(proc)\n",
    "    EachReviewText = proc\n",
    "    final_string.append(EachReviewText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "015003cb-e4af-46b4-beda-0d3edcd58bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"step01\"] = final_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99246677-a758-48f3-9af7-fb4f31a48aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>step01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dzikir Nasional Siapkan Spiritual untuk Lebih ...</td>\n",
       "      <td>REPUBLIKA.CO.ID, JAKARTA -- Dzikir Nasional 20...</td>\n",
       "      <td>republika co id jakarta dzikir nasional   bert...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Dzikir Nasional Siapkan Spiritual untuk Lebih ...   \n",
       "\n",
       "                                             content  \\\n",
       "0  REPUBLIKA.CO.ID, JAKARTA -- Dzikir Nasional 20...   \n",
       "\n",
       "                                              step01  \n",
       "0  republika co id jakarta dzikir nasional   bert...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f87c2c8e-0539-4c29-8c4c-08d020e3b4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 0 to 0\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   title    1 non-null      object\n",
      " 1   content  1 non-null      object\n",
      " 2   step01   1 non-null      object\n",
      "dtypes: object(3)\n",
      "memory usage: 156.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b482f02f-a9c8-4bd0-9744-992485aebb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hapus = df[~df['step01'].str.contains(\" \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "94a84b96-afba-4323-a954-76c983847326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 0 entries\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   title    0 non-null      object\n",
      " 1   content  0 non-null      object\n",
      " 2   step01   0 non-null      object\n",
      "dtypes: object(3)\n",
      "memory usage: 0.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_hapus.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ee2c6680-a60a-4626-8f92-538a3875bed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>step01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [title, content, step01]\n",
       "Index: []"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hapus.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55896d8a-1db2-438d-b113-8aada1164e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df[~df.isin(df_hapus)].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e230408e-8988-4a5c-bbab-13f2a6043814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 0 to 0\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   title    1 non-null      object\n",
      " 1   content  1 non-null      object\n",
      " 2   step01   1 non-null      object\n",
      "dtypes: object(3)\n",
      "memory usage: 156.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "faf68e66-2b0b-403e-84d7-5e3c91683d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>step01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dzikir Nasional Siapkan Spiritual untuk Lebih ...</td>\n",
       "      <td>REPUBLIKA.CO.ID, JAKARTA -- Dzikir Nasional 20...</td>\n",
       "      <td>republika co id jakarta dzikir nasional   bert...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Dzikir Nasional Siapkan Spiritual untuk Lebih ...   \n",
       "\n",
       "                                             content  \\\n",
       "0  REPUBLIKA.CO.ID, JAKARTA -- Dzikir Nasional 20...   \n",
       "\n",
       "                                              step01  \n",
       "0  republika co id jakarta dzikir nasional   bert...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163e0f11-c41b-4912-b8fc-2414f60a73b8",
   "metadata": {},
   "source": [
    "normalisasi kata slang menjadi kata baku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "96c17683-89d2-4a88-8552-d00ba3c6f5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# token\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b982b19-a730-4332-ba8f-de4c3835d33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_tokenize_wrapper(text):\n",
    "  return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c3b6883-292f-4f89-b2de-335cc65b2b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['tokens'] = df['step01'].apply(word_tokenize_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1abb9818-4c85-4ce7-97fa-1feb278a7017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>step01</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dzikir Nasional Siapkan Spiritual untuk Lebih ...</td>\n",
       "      <td>REPUBLIKA.CO.ID, JAKARTA -- Dzikir Nasional 20...</td>\n",
       "      <td>republika co id jakarta dzikir nasional   bert...</td>\n",
       "      <td>[republika, co, id, jakarta, dzikir, nasional,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Dzikir Nasional Siapkan Spiritual untuk Lebih ...   \n",
       "\n",
       "                                             content  \\\n",
       "0  REPUBLIKA.CO.ID, JAKARTA -- Dzikir Nasional 20...   \n",
       "\n",
       "                                              step01  \\\n",
       "0  republika co id jakarta dzikir nasional   bert...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [republika, co, id, jakarta, dzikir, nasional,...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d69e6541-84de-473f-834d-d3af48fb44b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_word = pd.read_csv('kamus_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0656de89-f9b4-473d-85a9-9c5bf4db6237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmahf\\AppData\\Local\\Temp\\ipykernel_3380\\2408214049.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if row[0] not in normalized_word_dict:\n",
      "C:\\Users\\mmahf\\AppData\\Local\\Temp\\ipykernel_3380\\2408214049.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  normalized_word_dict[row[0]] = row[1]\n"
     ]
    }
   ],
   "source": [
    "normalized_word_dict = {}\n",
    "\n",
    "for index, row in normalized_word.iterrows():\n",
    "    if row[0] not in normalized_word_dict:\n",
    "        normalized_word_dict[row[0]] = row[1] \n",
    "\n",
    "def normalized_term(document):\n",
    "    return [normalized_word_dict[term] if term in normalized_word_dict else term for term in document]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cb1c720f-da2a-4c18-99cd-ece8e4b98d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['final_tokens'] = df_new['tokens'].apply(normalized_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2f8b0b8d-13a5-4328-a9fb-784606a8b015",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "final_string_tokens = []\n",
    "for text in df_new['final_tokens'].values:\n",
    "    EachReviewText = \"\"\n",
    "    EachReviewText = ' '.join(text)\n",
    "    final_string_tokens.append(EachReviewText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4c03f50a-6be9-4a1f-823f-aa8e48c95680",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new[\"step02\"] = final_string_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "37709e53-7e04-49ab-9c5f-a8d94c63d0d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>step01</th>\n",
       "      <th>tokens</th>\n",
       "      <th>final_tokens</th>\n",
       "      <th>step02</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dzikir Nasional Siapkan Spiritual untuk Lebih ...</td>\n",
       "      <td>REPUBLIKA.CO.ID, JAKARTA -- Dzikir Nasional 20...</td>\n",
       "      <td>republika co id jakarta dzikir nasional   bert...</td>\n",
       "      <td>[republika, co, id, jakarta, dzikir, nasional,...</td>\n",
       "      <td>[republika, co, id, jakarta, dzikir, nasional,...</td>\n",
       "      <td>republika co id jakarta dzikir nasional bertuj...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Dzikir Nasional Siapkan Spiritual untuk Lebih ...   \n",
       "\n",
       "                                             content  \\\n",
       "0  REPUBLIKA.CO.ID, JAKARTA -- Dzikir Nasional 20...   \n",
       "\n",
       "                                              step01  \\\n",
       "0  republika co id jakarta dzikir nasional   bert...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [republika, co, id, jakarta, dzikir, nasional,...   \n",
       "\n",
       "                                        final_tokens  \\\n",
       "0  [republika, co, id, jakarta, dzikir, nasional,...   \n",
       "\n",
       "                                              step02  \n",
       "0  republika co id jakarta dzikir nasional bertuj...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b19e71dc-0221-45db-b416-a0e6f502d462",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('clean_dataset2.csv',sep=\";\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
